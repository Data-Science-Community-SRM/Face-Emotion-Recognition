{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1./255,rotation_range=15,\n                                    width_shift_range=0.15,\n                                    height_shift_range=0.15,\n                                    shear_range=0.15,\n                                    zoom_range=0.15,\n                                    horizontal_flip=True,\n                                  )\nval_datagen = ImageDataGenerator(rescale=1./255)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Batch Size and Image Size\nbatch_sz = 64\nsz = 48\n\ntrain_generator = train_datagen.flow_from_directory('../input/fer-dsc-v3/final_data_v5/final_data_v5/Train',\n                                                    batch_size = batch_sz,\n                                                    class_mode='categorical',\n                                                    target_size=(sz,sz))\n\nval_generator = val_datagen.flow_from_directory('../input/fer-dsc-v3/final_data_v5/final_data_v5/Test',\n                                                    batch_size = batch_sz,\n                                                    class_mode='categorical',\n                                                    target_size=(sz,sz))","execution_count":3,"outputs":[{"output_type":"stream","text":"Found 13651 images belonging to 4 classes.\nFound 1649 images belonging to 4 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('val_accuracy')>0.74):\n#             if(logs.get('accuracy')>78):\n                print(\"\\nReached 74% val_accuracy, so cancelling training!\")\n                self.model.stop_training = True\ncallbacks = myCallback()'''","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"'class myCallback(tf.keras.callbacks.Callback):\\n    def on_epoch_end(self, epoch, logs={}):\\n        if(logs.get(\\'val_accuracy\\')>0.74):\\n#             if(logs.get(\\'accuracy\\')>78):\\n                print(\"\\nReached 74% val_accuracy, so cancelling training!\")\\n                self.model.stop_training = True\\ncallbacks = myCallback()'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.vgg16 import VGG16","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_model = VGG16(include_top = False,\n                 weights = 'imagenet',\n                 input_shape = (48,48,3))","execution_count":6,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58892288/58889256 [==============================] - 0s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in pre_model.layers:\n    layer.trainable=False","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_output = pre_model.get_layer('block5_conv1').output","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = tf.keras.layers.GlobalAveragePooling2D()(last_output)\nx = tf.keras.layers.Flatten()(last_output)\nx = tf.keras.layers.Dense(256,activation='relu')(x)\nx = tf.keras.layers.Dropout(0.4)(x)\nx = tf.keras.layers.Dense(128,activation= 'relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.Dense(4,activation='softmax')(x)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Model(pre_model.input, x)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = tf.keras.optimizers.RMSprop(learning_rate=1e-5)\nmodel.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_generator,\n                   validation_data=val_generator,\n                    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n                   validation_steps=val_generator.samples//val_generator.batch_size,\n                    epochs=30\n                    )","execution_count":null,"outputs":[{"output_type":"stream","text":"Epoch 1/30\n213/213 [==============================] - 44s 208ms/step - loss: 1.9499 - accuracy: 0.2619 - val_loss: 1.4088 - val_accuracy: 0.3275\nEpoch 2/30\n213/213 [==============================] - 26s 122ms/step - loss: 1.5160 - accuracy: 0.2926 - val_loss: 1.3444 - val_accuracy: 0.3681\nEpoch 3/30\n213/213 [==============================] - 26s 123ms/step - loss: 1.4181 - accuracy: 0.3115 - val_loss: 1.3084 - val_accuracy: 0.3994\nEpoch 4/30\n213/213 [==============================] - 26s 121ms/step - loss: 1.3835 - accuracy: 0.3269 - val_loss: 1.2961 - val_accuracy: 0.4238\nEpoch 5/30\n213/213 [==============================] - 26s 123ms/step - loss: 1.3644 - accuracy: 0.3424 - val_loss: 1.2858 - val_accuracy: 0.4300\nEpoch 6/30\n213/213 [==============================] - 26s 120ms/step - loss: 1.3472 - accuracy: 0.3541 - val_loss: 1.2753 - val_accuracy: 0.4294\nEpoch 7/30\n213/213 [==============================] - 26s 121ms/step - loss: 1.3341 - accuracy: 0.3665 - val_loss: 1.2655 - val_accuracy: 0.4431\nEpoch 8/30\n213/213 [==============================] - 25s 119ms/step - loss: 1.3270 - accuracy: 0.3747 - val_loss: 1.2498 - val_accuracy: 0.4563\nEpoch 9/30\n213/213 [==============================] - 27s 125ms/step - loss: 1.3129 - accuracy: 0.3870 - val_loss: 1.2488 - val_accuracy: 0.4494\nEpoch 10/30\n213/213 [==============================] - 25s 117ms/step - loss: 1.3087 - accuracy: 0.3890 - val_loss: 1.2329 - val_accuracy: 0.4650\nEpoch 11/30\n213/213 [==============================] - 25s 118ms/step - loss: 1.3070 - accuracy: 0.3957 - val_loss: 1.2392 - val_accuracy: 0.4600\nEpoch 12/30\n213/213 [==============================] - 26s 122ms/step - loss: 1.3042 - accuracy: 0.3952 - val_loss: 1.2224 - val_accuracy: 0.4706\nEpoch 13/30\n192/213 [==========================>...] - ETA: 2s - loss: 1.2939 - accuracy: 0.4016","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in model.layers:\n    layer.trainable = True\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt1 = tf.keras.optimizers.Adam(learning_rate = 1e-4)\nmodel.compile(optimizer = opt1, loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history1 = model.fit(train_generator,\n                    validation_data = val_generator,\n                    validation_steps = val_generator.samples // val_generator.batch_size,\n                    epochs = 22)\n                    #callbacks = [callbacks])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = 22\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), history1.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), history1.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), history1.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), history1.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy on FER Dataset\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"lower left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('VGG_16_modified.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('VGG16_modified_weights.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import model_from_json\n# serialize model to json\njson_model = model.to_json()\n#save the model architecture to JSON file\nwith open('VGG16_modified_model.json', 'w') as json_file:\n    json_file.write(json_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = '../input/fer-dsc-v3/final_data_v5/final_data_v5/Test'\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_directory (test, batch_size=64, class_mode='categorical', target_size=(48,48))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(test_generator, steps=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''import numpy as np\nimport files\nfrom keras.preprocessing import image\n\nuploaded = files.upload()\n\n# predicting images\nfor fn in uploaded.keys():\n    path = fn\n    img = image.load_img(path, target_size=(48, 48))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n\n    images = np.vstack([x])\n    classes = model.predict(images, batch_size=10)\n    print(fn)\n    print(classes)'''","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}