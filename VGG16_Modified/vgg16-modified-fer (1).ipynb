{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1./255,rotation_range=15,\n                                    width_shift_range=0.15,\n                                    height_shift_range=0.15,\n                                    shear_range=0.15,\n                                    zoom_range=0.15,\n                                    horizontal_flip=True,\n                                  )\nval_datagen = ImageDataGenerator(rescale=1./255)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Batch Size and Image Size\nbatch_sz = 64\nsz = 48\n\ntrain_generator = train_datagen.flow_from_directory('../input/fer-dsc-v3/final_data_v5/final_data_v5/Train',\n                                                    batch_size = batch_sz,\n                                                    class_mode='categorical',\n                                                    target_size=(sz,sz))\n\nval_generator = val_datagen.flow_from_directory('../input/fer-dsc-v3/final_data_v5/final_data_v5/Test',\n                                                    batch_size = batch_sz,\n                                                    class_mode='categorical',\n                                                    target_size=(sz,sz))","execution_count":3,"outputs":[{"output_type":"stream","text":"Found 13651 images belonging to 4 classes.\nFound 1649 images belonging to 4 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('val_accuracy')>0.74):\n#             if(logs.get('accuracy')>78):\n                print(\"\\nReached 74% val_accuracy, so cancelling training!\")\n                self.model.stop_training = True\ncallbacks = myCallback()'''","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"'class myCallback(tf.keras.callbacks.Callback):\\n    def on_epoch_end(self, epoch, logs={}):\\n        if(logs.get(\\'val_accuracy\\')>0.74):\\n#             if(logs.get(\\'accuracy\\')>78):\\n                print(\"\\nReached 74% val_accuracy, so cancelling training!\")\\n                self.model.stop_training = True\\ncallbacks = myCallback()'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.vgg16 import VGG16","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_model = VGG16(include_top = False,\n                 weights = 'imagenet',\n                 input_shape = (48,48,3))","execution_count":6,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58892288/58889256 [==============================] - 0s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in pre_model.layers:\n    layer.trainable=False","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_output = pre_model.get_layer('block5_conv1').output","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = tf.keras.layers.GlobalAveragePooling2D()(last_output)\nx = tf.keras.layers.Flatten()(last_output)\nx = tf.keras.layers.Dense(256,activation='relu')(x)\nx = tf.keras.layers.Dropout(0.4)(x)\nx = tf.keras.layers.Dense(128,activation= 'relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.Dense(4,activation='softmax')(x)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Model(pre_model.input, x)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = tf.keras.optimizers.RMSprop(learning_rate=1e-5)\nmodel.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_generator,\n                   validation_data=val_generator,\n                    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n                   validation_steps=val_generator.samples//val_generator.batch_size,\n                    epochs=30\n                    )","execution_count":12,"outputs":[{"output_type":"stream","text":"Epoch 1/30\n213/213 [==============================] - 39s 181ms/step - loss: 1.9400 - accuracy: 0.2647 - val_loss: 1.3947 - val_accuracy: 0.3169\nEpoch 2/30\n213/213 [==============================] - 21s 97ms/step - loss: 1.5044 - accuracy: 0.2917 - val_loss: 1.3369 - val_accuracy: 0.3625\nEpoch 3/30\n213/213 [==============================] - 21s 96ms/step - loss: 1.4159 - accuracy: 0.3157 - val_loss: 1.3150 - val_accuracy: 0.3819\nEpoch 4/30\n213/213 [==============================] - 22s 102ms/step - loss: 1.3873 - accuracy: 0.3240 - val_loss: 1.3076 - val_accuracy: 0.3812\nEpoch 5/30\n213/213 [==============================] - 22s 101ms/step - loss: 1.3585 - accuracy: 0.3500 - val_loss: 1.2903 - val_accuracy: 0.4081\nEpoch 6/30\n213/213 [==============================] - 20s 96ms/step - loss: 1.3393 - accuracy: 0.3650 - val_loss: 1.2757 - val_accuracy: 0.4231\nEpoch 7/30\n213/213 [==============================] - 21s 99ms/step - loss: 1.3307 - accuracy: 0.3657 - val_loss: 1.2636 - val_accuracy: 0.4187\nEpoch 8/30\n213/213 [==============================] - 21s 97ms/step - loss: 1.3244 - accuracy: 0.3687 - val_loss: 1.2623 - val_accuracy: 0.4238\nEpoch 9/30\n213/213 [==============================] - 20s 95ms/step - loss: 1.3189 - accuracy: 0.3812 - val_loss: 1.2518 - val_accuracy: 0.4331\nEpoch 10/30\n213/213 [==============================] - 21s 100ms/step - loss: 1.3138 - accuracy: 0.3844 - val_loss: 1.2407 - val_accuracy: 0.4406\nEpoch 11/30\n213/213 [==============================] - 21s 98ms/step - loss: 1.2976 - accuracy: 0.3952 - val_loss: 1.2408 - val_accuracy: 0.4319\nEpoch 12/30\n213/213 [==============================] - 21s 97ms/step - loss: 1.3003 - accuracy: 0.3946 - val_loss: 1.2312 - val_accuracy: 0.4487\nEpoch 13/30\n213/213 [==============================] - 21s 99ms/step - loss: 1.2925 - accuracy: 0.4068 - val_loss: 1.2200 - val_accuracy: 0.4512\nEpoch 14/30\n213/213 [==============================] - 21s 97ms/step - loss: 1.2862 - accuracy: 0.4008 - val_loss: 1.2176 - val_accuracy: 0.4462\nEpoch 15/30\n213/213 [==============================] - 20s 95ms/step - loss: 1.2783 - accuracy: 0.4131 - val_loss: 1.2131 - val_accuracy: 0.4487\nEpoch 16/30\n213/213 [==============================] - 22s 101ms/step - loss: 1.2691 - accuracy: 0.4212 - val_loss: 1.2088 - val_accuracy: 0.4575\nEpoch 17/30\n213/213 [==============================] - 21s 97ms/step - loss: 1.2614 - accuracy: 0.4228 - val_loss: 1.2054 - val_accuracy: 0.4531\nEpoch 18/30\n213/213 [==============================] - 20s 96ms/step - loss: 1.2722 - accuracy: 0.4161 - val_loss: 1.2048 - val_accuracy: 0.4569\nEpoch 19/30\n213/213 [==============================] - 21s 100ms/step - loss: 1.2621 - accuracy: 0.4264 - val_loss: 1.2004 - val_accuracy: 0.4544\nEpoch 20/30\n213/213 [==============================] - 21s 97ms/step - loss: 1.2571 - accuracy: 0.4285 - val_loss: 1.1983 - val_accuracy: 0.4619\nEpoch 21/30\n213/213 [==============================] - 21s 97ms/step - loss: 1.2511 - accuracy: 0.4307 - val_loss: 1.1852 - val_accuracy: 0.4688\nEpoch 22/30\n213/213 [==============================] - 21s 96ms/step - loss: 1.2476 - accuracy: 0.4403 - val_loss: 1.1808 - val_accuracy: 0.4681\nEpoch 23/30\n213/213 [==============================] - 21s 96ms/step - loss: 1.2476 - accuracy: 0.4342 - val_loss: 1.1811 - val_accuracy: 0.4775\nEpoch 24/30\n213/213 [==============================] - 21s 98ms/step - loss: 1.2370 - accuracy: 0.4453 - val_loss: 1.1671 - val_accuracy: 0.4856\nEpoch 25/30\n213/213 [==============================] - 20s 96ms/step - loss: 1.2348 - accuracy: 0.4467 - val_loss: 1.1776 - val_accuracy: 0.4744\nEpoch 26/30\n213/213 [==============================] - 20s 96ms/step - loss: 1.2296 - accuracy: 0.4431 - val_loss: 1.1651 - val_accuracy: 0.4881\nEpoch 27/30\n213/213 [==============================] - 21s 97ms/step - loss: 1.2288 - accuracy: 0.4449 - val_loss: 1.1631 - val_accuracy: 0.4787\nEpoch 28/30\n213/213 [==============================] - 20s 96ms/step - loss: 1.2275 - accuracy: 0.4484 - val_loss: 1.1537 - val_accuracy: 0.4881\nEpoch 29/30\n213/213 [==============================] - 20s 96ms/step - loss: 1.2289 - accuracy: 0.4465 - val_loss: 1.1518 - val_accuracy: 0.4975\nEpoch 30/30\n213/213 [==============================] - 21s 98ms/step - loss: 1.2194 - accuracy: 0.4528 - val_loss: 1.1595 - val_accuracy: 0.4888\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in model.layers:\n    layer.trainable = True\n","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.summary())","execution_count":14,"outputs":[{"output_type":"stream","text":"Model: \"functional_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 48, 48, 3)]       0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n_________________________________________________________________\nflatten (Flatten)            (None, 4608)              0         \n_________________________________________________________________\ndense (Dense)                (None, 256)               1179904   \n_________________________________________________________________\ndropout (Dropout)            (None, 256)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               32896     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 4)                 516       \n=================================================================\nTotal params: 11,208,388\nTrainable params: 11,208,388\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt1 = tf.keras.optimizers.Adam(learning_rate = 1e-4)\nmodel.compile(optimizer = opt1, loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history1 = model.fit(train_generator,\n                    validation_data = val_generator,\n                    validation_steps = val_generator.samples // val_generator.batch_size,\n                    epochs = 22)\n                    #callbacks = [callbacks])","execution_count":16,"outputs":[{"output_type":"stream","text":"Epoch 1/22\n214/214 [==============================] - 22s 104ms/step - loss: 1.2287 - accuracy: 0.4233 - val_loss: 0.9756 - val_accuracy: 0.5725\nEpoch 2/22\n214/214 [==============================] - 22s 103ms/step - loss: 0.9882 - accuracy: 0.5757 - val_loss: 0.9748 - val_accuracy: 0.5819\nEpoch 3/22\n214/214 [==============================] - 23s 105ms/step - loss: 0.8923 - accuracy: 0.6264 - val_loss: 0.7625 - val_accuracy: 0.6756\nEpoch 4/22\n214/214 [==============================] - 23s 106ms/step - loss: 0.8404 - accuracy: 0.6568 - val_loss: 0.7600 - val_accuracy: 0.6787\nEpoch 5/22\n214/214 [==============================] - 23s 106ms/step - loss: 0.7906 - accuracy: 0.6756 - val_loss: 0.7384 - val_accuracy: 0.6925\nEpoch 6/22\n214/214 [==============================] - 22s 102ms/step - loss: 0.7671 - accuracy: 0.6874 - val_loss: 0.6905 - val_accuracy: 0.7106\nEpoch 7/22\n214/214 [==============================] - 22s 102ms/step - loss: 0.7385 - accuracy: 0.7009 - val_loss: 0.6836 - val_accuracy: 0.7281\nEpoch 8/22\n214/214 [==============================] - 23s 107ms/step - loss: 0.7076 - accuracy: 0.7180 - val_loss: 0.7073 - val_accuracy: 0.7181\nEpoch 9/22\n214/214 [==============================] - 22s 103ms/step - loss: 0.6869 - accuracy: 0.7240 - val_loss: 0.7150 - val_accuracy: 0.7125\nEpoch 10/22\n214/214 [==============================] - 22s 103ms/step - loss: 0.6645 - accuracy: 0.7326 - val_loss: 0.6695 - val_accuracy: 0.7281\nEpoch 11/22\n214/214 [==============================] - 22s 105ms/step - loss: 0.6461 - accuracy: 0.7439 - val_loss: 0.6854 - val_accuracy: 0.7319\nEpoch 12/22\n214/214 [==============================] - 22s 102ms/step - loss: 0.6272 - accuracy: 0.7514 - val_loss: 0.6539 - val_accuracy: 0.7356\nEpoch 13/22\n214/214 [==============================] - 22s 104ms/step - loss: 0.6026 - accuracy: 0.7612 - val_loss: 0.6720 - val_accuracy: 0.7400\nEpoch 14/22\n214/214 [==============================] - 22s 103ms/step - loss: 0.5861 - accuracy: 0.7732 - val_loss: 0.6875 - val_accuracy: 0.7400\nEpoch 15/22\n214/214 [==============================] - 22s 102ms/step - loss: 0.5592 - accuracy: 0.7813 - val_loss: 0.6450 - val_accuracy: 0.7506\nEpoch 16/22\n214/214 [==============================] - 23s 107ms/step - loss: 0.5443 - accuracy: 0.7901 - val_loss: 0.6950 - val_accuracy: 0.7387\nEpoch 17/22\n214/214 [==============================] - 22s 104ms/step - loss: 0.5231 - accuracy: 0.7970 - val_loss: 0.6788 - val_accuracy: 0.7431\nEpoch 18/22\n214/214 [==============================] - 23s 108ms/step - loss: 0.5074 - accuracy: 0.8035 - val_loss: 0.6879 - val_accuracy: 0.7456\nEpoch 19/22\n214/214 [==============================] - 23s 108ms/step - loss: 0.4954 - accuracy: 0.8093 - val_loss: 0.7230 - val_accuracy: 0.7331\nEpoch 20/22\n214/214 [==============================] - 22s 103ms/step - loss: 0.4764 - accuracy: 0.8150 - val_loss: 0.7087 - val_accuracy: 0.7531\nEpoch 21/22\n214/214 [==============================] - 22s 104ms/step - loss: 0.4595 - accuracy: 0.8257 - val_loss: 0.6897 - val_accuracy: 0.7431\nEpoch 22/22\n214/214 [==============================] - 22s 104ms/step - loss: 0.4443 - accuracy: 0.8259 - val_loss: 0.7115 - val_accuracy: 0.7519\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = 22\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), history1.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), history1.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), history1.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), history1.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy on FER Dataset\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"lower left\")","execution_count":17,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"x and y must have same first dimension, but have shapes (25,) and (22,)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-778907333b2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ggplot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \"\"\"\n\u001b[1;32m   1645\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (25,) and (22,)"]},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('VGG_16_modified.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('VGG16_modified_weights.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import model_from_json\n# serialize model to json\njson_model = model.to_json()\n#save the model architecture to JSON file\nwith open('VGG16_modified_model.json', 'w') as json_file:\n    json_file.write(json_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = '../input/fer-dsc-v3/final_data_v5/final_data_v5/Test'\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_directory (test, batch_size=256, class_mode='categorical', target_size=(48,48))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate(test_generator, steps=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''import numpy as np\nimport files\nfrom keras.preprocessing import image\n\nuploaded = files.upload()\n\n# predicting images\nfor fn in uploaded.keys():\n    path = fn\n    img = image.load_img(path, target_size=(48, 48))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n\n    images = np.vstack([x])\n    classes = model.predict(images, batch_size=10)\n    print(fn)\n    print(classes)'''","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}