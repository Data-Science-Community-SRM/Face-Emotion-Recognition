{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport tensorflow\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nimport tensorflow as tf\npre_model= tf.keras.applications.VGG16(include_top=False,\n                             weights='imagenet',\n                             input_shape=(150,150,3))\n                             \n                             '''\n\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_datagen = ImageDataGenerator(rescale = 1./255,rotation_range=15,\n                                    width_shift_range=0.15,\n                                    height_shift_range=0.15,\n                                    shear_range=0.15,\n                                    zoom_range=0.15,\n                                    horizontal_flip=True,\n                                  )\nval_datagen = ImageDataGenerator(rescale=1./255)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Batch Size and Image Size\nbatch_sz = 64\nsz = 48\n\ntrain_generator = train_datagen.flow_from_directory('../input/fer-dsc-v3/final_data_v5/final_data_v5/Train',\n                                                    batch_size = batch_sz,\n                                                    class_mode='categorical',\n                                                    target_size=(sz,sz))\n\nval_generator = val_datagen.flow_from_directory('../input/fer-dsc-v3/final_data_v5/final_data_v5/Test',\n                                                    batch_size = batch_sz,\n                                                    class_mode='categorical',\n                                                    target_size=(sz,sz))","execution_count":4,"outputs":[{"output_type":"stream","text":"Found 13651 images belonging to 4 classes.\nFound 1649 images belonging to 4 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50\n\npre_model = ResNet50(include_top = False,\n                 weights = 'imagenet',\n                 input_shape = (48,48,3))\n\nfor layer in pre_model.layers:\n    layer.trainable=False\n\nlast_output = pre_model.output","execution_count":5,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94773248/94765736 [==============================] - 1s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pre_model.summary()","execution_count":6,"outputs":[{"output_type":"stream","text":"Model: \"resnet50\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 48, 48, 3)]  0                                            \n__________________________________________________________________________________________________\nconv1_pad (ZeroPadding2D)       (None, 54, 54, 3)    0           input_1[0][0]                    \n__________________________________________________________________________________________________\nconv1_conv (Conv2D)             (None, 24, 24, 64)   9472        conv1_pad[0][0]                  \n__________________________________________________________________________________________________\nconv1_bn (BatchNormalization)   (None, 24, 24, 64)   256         conv1_conv[0][0]                 \n__________________________________________________________________________________________________\nconv1_relu (Activation)         (None, 24, 24, 64)   0           conv1_bn[0][0]                   \n__________________________________________________________________________________________________\npool1_pad (ZeroPadding2D)       (None, 26, 26, 64)   0           conv1_relu[0][0]                 \n__________________________________________________________________________________________________\npool1_pool (MaxPooling2D)       (None, 12, 12, 64)   0           pool1_pad[0][0]                  \n__________________________________________________________________________________________________\nconv2_block1_1_conv (Conv2D)    (None, 12, 12, 64)   4160        pool1_pool[0][0]                 \n__________________________________________________________________________________________________\nconv2_block1_1_bn (BatchNormali (None, 12, 12, 64)   256         conv2_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_1_relu (Activation (None, 12, 12, 64)   0           conv2_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_2_conv (Conv2D)    (None, 12, 12, 64)   36928       conv2_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_2_bn (BatchNormali (None, 12, 12, 64)   256         conv2_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_2_relu (Activation (None, 12, 12, 64)   0           conv2_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_0_conv (Conv2D)    (None, 12, 12, 256)  16640       pool1_pool[0][0]                 \n__________________________________________________________________________________________________\nconv2_block1_3_conv (Conv2D)    (None, 12, 12, 256)  16640       conv2_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_0_bn (BatchNormali (None, 12, 12, 256)  1024        conv2_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_3_bn (BatchNormali (None, 12, 12, 256)  1024        conv2_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_add (Add)          (None, 12, 12, 256)  0           conv2_block1_0_bn[0][0]          \n                                                                 conv2_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_out (Activation)   (None, 12, 12, 256)  0           conv2_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv2_block2_1_conv (Conv2D)    (None, 12, 12, 64)   16448       conv2_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv2_block2_1_bn (BatchNormali (None, 12, 12, 64)   256         conv2_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_1_relu (Activation (None, 12, 12, 64)   0           conv2_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_2_conv (Conv2D)    (None, 12, 12, 64)   36928       conv2_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_2_bn (BatchNormali (None, 12, 12, 64)   256         conv2_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_2_relu (Activation (None, 12, 12, 64)   0           conv2_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_3_conv (Conv2D)    (None, 12, 12, 256)  16640       conv2_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_3_bn (BatchNormali (None, 12, 12, 256)  1024        conv2_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_add (Add)          (None, 12, 12, 256)  0           conv2_block1_out[0][0]           \n                                                                 conv2_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_out (Activation)   (None, 12, 12, 256)  0           conv2_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv2_block3_1_conv (Conv2D)    (None, 12, 12, 64)   16448       conv2_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv2_block3_1_bn (BatchNormali (None, 12, 12, 64)   256         conv2_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_1_relu (Activation (None, 12, 12, 64)   0           conv2_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_2_conv (Conv2D)    (None, 12, 12, 64)   36928       conv2_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_2_bn (BatchNormali (None, 12, 12, 64)   256         conv2_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_2_relu (Activation (None, 12, 12, 64)   0           conv2_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_3_conv (Conv2D)    (None, 12, 12, 256)  16640       conv2_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_3_bn (BatchNormali (None, 12, 12, 256)  1024        conv2_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_add (Add)          (None, 12, 12, 256)  0           conv2_block2_out[0][0]           \n                                                                 conv2_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_out (Activation)   (None, 12, 12, 256)  0           conv2_block3_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block1_1_conv (Conv2D)    (None, 6, 6, 128)    32896       conv2_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block1_1_bn (BatchNormali (None, 6, 6, 128)    512         conv3_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_1_relu (Activation (None, 6, 6, 128)    0           conv3_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_2_conv (Conv2D)    (None, 6, 6, 128)    147584      conv3_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_2_bn (BatchNormali (None, 6, 6, 128)    512         conv3_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_2_relu (Activation (None, 6, 6, 128)    0           conv3_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_0_conv (Conv2D)    (None, 6, 6, 512)    131584      conv2_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block1_3_conv (Conv2D)    (None, 6, 6, 512)    66048       conv3_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_0_bn (BatchNormali (None, 6, 6, 512)    2048        conv3_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_3_bn (BatchNormali (None, 6, 6, 512)    2048        conv3_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_add (Add)          (None, 6, 6, 512)    0           conv3_block1_0_bn[0][0]          \n                                                                 conv3_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_out (Activation)   (None, 6, 6, 512)    0           conv3_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block2_1_conv (Conv2D)    (None, 6, 6, 128)    65664       conv3_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block2_1_bn (BatchNormali (None, 6, 6, 128)    512         conv3_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_1_relu (Activation (None, 6, 6, 128)    0           conv3_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_2_conv (Conv2D)    (None, 6, 6, 128)    147584      conv3_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_2_bn (BatchNormali (None, 6, 6, 128)    512         conv3_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_2_relu (Activation (None, 6, 6, 128)    0           conv3_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_3_conv (Conv2D)    (None, 6, 6, 512)    66048       conv3_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_3_bn (BatchNormali (None, 6, 6, 512)    2048        conv3_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_add (Add)          (None, 6, 6, 512)    0           conv3_block1_out[0][0]           \n                                                                 conv3_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_out (Activation)   (None, 6, 6, 512)    0           conv3_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block3_1_conv (Conv2D)    (None, 6, 6, 128)    65664       conv3_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block3_1_bn (BatchNormali (None, 6, 6, 128)    512         conv3_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_1_relu (Activation (None, 6, 6, 128)    0           conv3_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_2_conv (Conv2D)    (None, 6, 6, 128)    147584      conv3_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_2_bn (BatchNormali (None, 6, 6, 128)    512         conv3_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_2_relu (Activation (None, 6, 6, 128)    0           conv3_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_3_conv (Conv2D)    (None, 6, 6, 512)    66048       conv3_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_3_bn (BatchNormali (None, 6, 6, 512)    2048        conv3_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_add (Add)          (None, 6, 6, 512)    0           conv3_block2_out[0][0]           \n                                                                 conv3_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_out (Activation)   (None, 6, 6, 512)    0           conv3_block3_add[0][0]           \n__________________________________________________________________________________________________\nconv3_block4_1_conv (Conv2D)    (None, 6, 6, 128)    65664       conv3_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block4_1_bn (BatchNormali (None, 6, 6, 128)    512         conv3_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_1_relu (Activation (None, 6, 6, 128)    0           conv3_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_2_conv (Conv2D)    (None, 6, 6, 128)    147584      conv3_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_2_bn (BatchNormali (None, 6, 6, 128)    512         conv3_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_2_relu (Activation (None, 6, 6, 128)    0           conv3_block4_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_3_conv (Conv2D)    (None, 6, 6, 512)    66048       conv3_block4_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_3_bn (BatchNormali (None, 6, 6, 512)    2048        conv3_block4_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_add (Add)          (None, 6, 6, 512)    0           conv3_block3_out[0][0]           \n                                                                 conv3_block4_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_out (Activation)   (None, 6, 6, 512)    0           conv3_block4_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_1_conv (Conv2D)    (None, 3, 3, 256)    131328      conv3_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_1_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_1_relu (Activation (None, 3, 3, 256)    0           conv4_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_2_conv (Conv2D)    (None, 3, 3, 256)    590080      conv4_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_2_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_2_relu (Activation (None, 3, 3, 256)    0           conv4_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_0_conv (Conv2D)    (None, 3, 3, 1024)   525312      conv3_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_3_conv (Conv2D)    (None, 3, 3, 1024)   263168      conv4_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_0_bn (BatchNormali (None, 3, 3, 1024)   4096        conv4_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_3_bn (BatchNormali (None, 3, 3, 1024)   4096        conv4_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_add (Add)          (None, 3, 3, 1024)   0           conv4_block1_0_bn[0][0]          \n                                                                 conv4_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_out (Activation)   (None, 3, 3, 1024)   0           conv4_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block2_1_conv (Conv2D)    (None, 3, 3, 256)    262400      conv4_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block2_1_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_1_relu (Activation (None, 3, 3, 256)    0           conv4_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_2_conv (Conv2D)    (None, 3, 3, 256)    590080      conv4_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_relu (Activation (None, 3, 3, 256)    0           conv4_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_3_conv (Conv2D)    (None, 3, 3, 1024)   263168      conv4_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_3_bn (BatchNormali (None, 3, 3, 1024)   4096        conv4_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_add (Add)          (None, 3, 3, 1024)   0           conv4_block1_out[0][0]           \n                                                                 conv4_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_out (Activation)   (None, 3, 3, 1024)   0           conv4_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block3_1_conv (Conv2D)    (None, 3, 3, 256)    262400      conv4_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block3_1_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_1_relu (Activation (None, 3, 3, 256)    0           conv4_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_2_conv (Conv2D)    (None, 3, 3, 256)    590080      conv4_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_relu (Activation (None, 3, 3, 256)    0           conv4_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_3_conv (Conv2D)    (None, 3, 3, 1024)   263168      conv4_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_3_bn (BatchNormali (None, 3, 3, 1024)   4096        conv4_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_add (Add)          (None, 3, 3, 1024)   0           conv4_block2_out[0][0]           \n                                                                 conv4_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_out (Activation)   (None, 3, 3, 1024)   0           conv4_block3_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block4_1_conv (Conv2D)    (None, 3, 3, 256)    262400      conv4_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block4_1_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_1_relu (Activation (None, 3, 3, 256)    0           conv4_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_2_conv (Conv2D)    (None, 3, 3, 256)    590080      conv4_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_relu (Activation (None, 3, 3, 256)    0           conv4_block4_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_3_conv (Conv2D)    (None, 3, 3, 1024)   263168      conv4_block4_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_3_bn (BatchNormali (None, 3, 3, 1024)   4096        conv4_block4_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_add (Add)          (None, 3, 3, 1024)   0           conv4_block3_out[0][0]           \n                                                                 conv4_block4_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_out (Activation)   (None, 3, 3, 1024)   0           conv4_block4_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block5_1_conv (Conv2D)    (None, 3, 3, 256)    262400      conv4_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block5_1_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_1_relu (Activation (None, 3, 3, 256)    0           conv4_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_2_conv (Conv2D)    (None, 3, 3, 256)    590080      conv4_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_relu (Activation (None, 3, 3, 256)    0           conv4_block5_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_3_conv (Conv2D)    (None, 3, 3, 1024)   263168      conv4_block5_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_3_bn (BatchNormali (None, 3, 3, 1024)   4096        conv4_block5_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_add (Add)          (None, 3, 3, 1024)   0           conv4_block4_out[0][0]           \n                                                                 conv4_block5_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_out (Activation)   (None, 3, 3, 1024)   0           conv4_block5_add[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_1_conv (Conv2D)    (None, 3, 3, 256)    262400      conv4_block5_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_1_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_1_relu (Activation (None, 3, 3, 256)    0           conv4_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_2_conv (Conv2D)    (None, 3, 3, 256)    590080      conv4_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_bn (BatchNormali (None, 3, 3, 256)    1024        conv4_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_relu (Activation (None, 3, 3, 256)    0           conv4_block6_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_3_conv (Conv2D)    (None, 3, 3, 1024)   263168      conv4_block6_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_3_bn (BatchNormali (None, 3, 3, 1024)   4096        conv4_block6_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_add (Add)          (None, 3, 3, 1024)   0           conv4_block5_out[0][0]           \n                                                                 conv4_block6_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_out (Activation)   (None, 3, 3, 1024)   0           conv4_block6_add[0][0]           \n__________________________________________________________________________________________________\nconv5_block1_1_conv (Conv2D)    (None, 2, 2, 512)    524800      conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block1_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_1_relu (Activation (None, 2, 2, 512)    0           conv5_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_2_relu (Activation (None, 2, 2, 512)    0           conv5_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_0_conv (Conv2D)    (None, 2, 2, 2048)   2099200     conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block1_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_0_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block1_0_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_add (Add)          (None, 2, 2, 2048)   0           conv5_block1_0_bn[0][0]          \n                                                                 conv5_block1_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_out (Activation)   (None, 2, 2, 2048)   0           conv5_block1_add[0][0]           \n__________________________________________________________________________________________________\nconv5_block2_1_conv (Conv2D)    (None, 2, 2, 512)    1049088     conv5_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block2_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_1_relu (Activation (None, 2, 2, 512)    0           conv5_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_2_relu (Activation (None, 2, 2, 512)    0           conv5_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_add (Add)          (None, 2, 2, 2048)   0           conv5_block1_out[0][0]           \n                                                                 conv5_block2_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_out (Activation)   (None, 2, 2, 2048)   0           conv5_block2_add[0][0]           \n__________________________________________________________________________________________________\nconv5_block3_1_conv (Conv2D)    (None, 2, 2, 512)    1049088     conv5_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block3_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_1_relu (Activation (None, 2, 2, 512)    0           conv5_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_2_relu (Activation (None, 2, 2, 512)    0           conv5_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_add (Add)          (None, 2, 2, 2048)   0           conv5_block2_out[0][0]           \n                                                                 conv5_block3_3_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_out (Activation)   (None, 2, 2, 2048)   0           conv5_block3_add[0][0]           \n==================================================================================================\nTotal params: 23,587,712\nTrainable params: 0\nNon-trainable params: 23,587,712\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in pre_model.layers:\n    layer.trainable=False\n\nlast_output = pre_model.get_layer('conv2_block3_2_conv').output","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = tf.keras.layers.GlobalAveragePooling2D()(last_output)\nx = tf.keras.layers.Flatten()(last_output)\nx = tf.keras.layers.Dense(256,activation='relu')(x)\nx = tf.keras.layers.Dropout(0.4)(x)\nx = tf.keras.layers.Dense(128,activation= 'relu')(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.Dense(4,activation='softmax')(x)\n\nmodel = tf.keras.Model(pre_model.input, x)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = tf.keras.optimizers.RMSprop(learning_rate=1e-5)\nmodel.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n\nhistory = model.fit(train_generator,\n                   validation_data=val_generator,\n                    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n                   validation_steps=val_generator.samples//val_generator.batch_size,\n                    epochs=30\n                    )","execution_count":9,"outputs":[{"output_type":"stream","text":"Epoch 1/30\n213/213 [==============================] - 46s 215ms/step - loss: 1.4049 - accuracy: 0.2601 - val_loss: 1.3858 - val_accuracy: 0.2775\nEpoch 2/30\n213/213 [==============================] - 22s 104ms/step - loss: 1.3902 - accuracy: 0.2573 - val_loss: 1.3839 - val_accuracy: 0.2675\nEpoch 3/30\n213/213 [==============================] - 22s 103ms/step - loss: 1.3865 - accuracy: 0.2667 - val_loss: 1.3788 - val_accuracy: 0.2750\nEpoch 4/30\n213/213 [==============================] - 23s 106ms/step - loss: 1.3864 - accuracy: 0.2621 - val_loss: 1.3786 - val_accuracy: 0.2788\nEpoch 5/30\n213/213 [==============================] - 22s 103ms/step - loss: 1.3855 - accuracy: 0.2664 - val_loss: 1.3779 - val_accuracy: 0.2912\nEpoch 6/30\n213/213 [==============================] - 22s 103ms/step - loss: 1.3862 - accuracy: 0.2643 - val_loss: 1.3786 - val_accuracy: 0.2862\nEpoch 7/30\n213/213 [==============================] - 22s 104ms/step - loss: 1.3846 - accuracy: 0.2648 - val_loss: 1.3752 - val_accuracy: 0.2887\nEpoch 8/30\n213/213 [==============================] - 22s 102ms/step - loss: 1.3843 - accuracy: 0.2705 - val_loss: 1.3769 - val_accuracy: 0.2881\nEpoch 9/30\n213/213 [==============================] - 22s 103ms/step - loss: 1.3840 - accuracy: 0.2712 - val_loss: 1.3734 - val_accuracy: 0.2912\nEpoch 10/30\n213/213 [==============================] - 22s 102ms/step - loss: 1.3833 - accuracy: 0.2749 - val_loss: 1.3747 - val_accuracy: 0.3056\nEpoch 11/30\n213/213 [==============================] - 22s 103ms/step - loss: 1.3833 - accuracy: 0.2690 - val_loss: 1.3727 - val_accuracy: 0.2781\nEpoch 12/30\n213/213 [==============================] - 23s 107ms/step - loss: 1.3824 - accuracy: 0.2820 - val_loss: 1.3686 - val_accuracy: 0.3469\nEpoch 13/30\n213/213 [==============================] - 22s 103ms/step - loss: 1.3822 - accuracy: 0.2794 - val_loss: 1.3675 - val_accuracy: 0.3212\nEpoch 14/30\n213/213 [==============================] - 22s 103ms/step - loss: 1.3828 - accuracy: 0.2736 - val_loss: 1.3686 - val_accuracy: 0.2806\nEpoch 15/30\n213/213 [==============================] - 23s 107ms/step - loss: 1.3812 - accuracy: 0.2812 - val_loss: 1.3688 - val_accuracy: 0.3806\nEpoch 16/30\n213/213 [==============================] - 22s 102ms/step - loss: 1.3803 - accuracy: 0.2837 - val_loss: 1.3689 - val_accuracy: 0.2713\nEpoch 17/30\n213/213 [==============================] - 22s 104ms/step - loss: 1.3821 - accuracy: 0.2774 - val_loss: 1.3669 - val_accuracy: 0.3519\nEpoch 18/30\n213/213 [==============================] - 23s 107ms/step - loss: 1.3805 - accuracy: 0.2821 - val_loss: 1.3650 - val_accuracy: 0.3781\nEpoch 19/30\n213/213 [==============================] - 22s 105ms/step - loss: 1.3796 - accuracy: 0.2827 - val_loss: 1.3621 - val_accuracy: 0.3956\nEpoch 20/30\n213/213 [==============================] - 23s 110ms/step - loss: 1.3793 - accuracy: 0.2828 - val_loss: 1.3604 - val_accuracy: 0.3600\nEpoch 21/30\n213/213 [==============================] - 22s 103ms/step - loss: 1.3791 - accuracy: 0.2849 - val_loss: 1.3586 - val_accuracy: 0.3750\nEpoch 22/30\n213/213 [==============================] - 22s 104ms/step - loss: 1.3784 - accuracy: 0.2865 - val_loss: 1.3570 - val_accuracy: 0.4019\nEpoch 23/30\n213/213 [==============================] - 23s 110ms/step - loss: 1.3776 - accuracy: 0.2941 - val_loss: 1.3530 - val_accuracy: 0.3775\nEpoch 24/30\n213/213 [==============================] - 22s 103ms/step - loss: 1.3762 - accuracy: 0.2945 - val_loss: 1.3519 - val_accuracy: 0.3331\nEpoch 25/30\n213/213 [==============================] - 22s 105ms/step - loss: 1.3764 - accuracy: 0.2937 - val_loss: 1.3511 - val_accuracy: 0.3850\nEpoch 26/30\n213/213 [==============================] - 23s 109ms/step - loss: 1.3761 - accuracy: 0.2950 - val_loss: 1.3505 - val_accuracy: 0.3544\nEpoch 27/30\n213/213 [==============================] - 22s 105ms/step - loss: 1.3750 - accuracy: 0.3010 - val_loss: 1.3474 - val_accuracy: 0.3756\nEpoch 28/30\n213/213 [==============================] - 23s 108ms/step - loss: 1.3753 - accuracy: 0.2982 - val_loss: 1.3462 - val_accuracy: 0.3688\nEpoch 29/30\n213/213 [==============================] - 22s 105ms/step - loss: 1.3730 - accuracy: 0.3040 - val_loss: 1.3445 - val_accuracy: 0.3988\nEpoch 30/30\n213/213 [==============================] - 23s 107ms/step - loss: 1.3733 - accuracy: 0.2995 - val_loss: 1.3399 - val_accuracy: 0.4250\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in model.layers:\n    layer.trainable = True","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt1 = tf.keras.optimizers.Adam(learning_rate = 1e-4)\nmodel.compile(optimizer = opt1, loss='categorical_crossentropy', metrics=['accuracy'])\n\nhistory1 = model.fit(train_generator,\n                    validation_data = val_generator,\n                    validation_steps = val_generator.samples // val_generator.batch_size,\n                    epochs = 100)\n                    #callbacks = [callbacks])","execution_count":11,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n214/214 [==============================] - 24s 112ms/step - loss: 1.3889 - accuracy: 0.3253 - val_loss: 1.4611 - val_accuracy: 0.2969\nEpoch 2/100\n214/214 [==============================] - 22s 105ms/step - loss: 1.2824 - accuracy: 0.3937 - val_loss: 1.7915 - val_accuracy: 0.2625\nEpoch 3/100\n214/214 [==============================] - 24s 111ms/step - loss: 1.2119 - accuracy: 0.4442 - val_loss: 1.2915 - val_accuracy: 0.3569\nEpoch 4/100\n214/214 [==============================] - 24s 110ms/step - loss: 1.1397 - accuracy: 0.4833 - val_loss: 1.1475 - val_accuracy: 0.5038\nEpoch 5/100\n214/214 [==============================] - 22s 105ms/step - loss: 1.1024 - accuracy: 0.5137 - val_loss: 1.0623 - val_accuracy: 0.5475\nEpoch 6/100\n214/214 [==============================] - 23s 109ms/step - loss: 1.0546 - accuracy: 0.5366 - val_loss: 1.0346 - val_accuracy: 0.5663\nEpoch 7/100\n214/214 [==============================] - 23s 106ms/step - loss: 1.0245 - accuracy: 0.5509 - val_loss: 0.9483 - val_accuracy: 0.5825\nEpoch 8/100\n214/214 [==============================] - 23s 107ms/step - loss: 0.9939 - accuracy: 0.5687 - val_loss: 1.0068 - val_accuracy: 0.5713\nEpoch 9/100\n214/214 [==============================] - 23s 105ms/step - loss: 0.9738 - accuracy: 0.5834 - val_loss: 0.8908 - val_accuracy: 0.6037\nEpoch 10/100\n214/214 [==============================] - 23s 106ms/step - loss: 0.9550 - accuracy: 0.5895 - val_loss: 0.8414 - val_accuracy: 0.6363\nEpoch 11/100\n214/214 [==============================] - 23s 109ms/step - loss: 0.9365 - accuracy: 0.6018 - val_loss: 0.8620 - val_accuracy: 0.6231\nEpoch 12/100\n214/214 [==============================] - 22s 105ms/step - loss: 0.9170 - accuracy: 0.6114 - val_loss: 0.8683 - val_accuracy: 0.6137\nEpoch 13/100\n214/214 [==============================] - 22s 105ms/step - loss: 0.9031 - accuracy: 0.6167 - val_loss: 0.8490 - val_accuracy: 0.6269\nEpoch 14/100\n214/214 [==============================] - 24s 111ms/step - loss: 0.8966 - accuracy: 0.6204 - val_loss: 0.8497 - val_accuracy: 0.6144\nEpoch 15/100\n214/214 [==============================] - 23s 106ms/step - loss: 0.8790 - accuracy: 0.6356 - val_loss: 0.8066 - val_accuracy: 0.6587\nEpoch 16/100\n214/214 [==============================] - 23s 108ms/step - loss: 0.8613 - accuracy: 0.6387 - val_loss: 0.7840 - val_accuracy: 0.6737\nEpoch 17/100\n214/214 [==============================] - 23s 108ms/step - loss: 0.8533 - accuracy: 0.6396 - val_loss: 0.7788 - val_accuracy: 0.6787\nEpoch 18/100\n214/214 [==============================] - 22s 105ms/step - loss: 0.8483 - accuracy: 0.6479 - val_loss: 0.8971 - val_accuracy: 0.6137\nEpoch 19/100\n214/214 [==============================] - 24s 110ms/step - loss: 0.8361 - accuracy: 0.6471 - val_loss: 0.7991 - val_accuracy: 0.6737\nEpoch 20/100\n214/214 [==============================] - 22s 105ms/step - loss: 0.8325 - accuracy: 0.6527 - val_loss: 0.7906 - val_accuracy: 0.6706\nEpoch 21/100\n214/214 [==============================] - 23s 106ms/step - loss: 0.8234 - accuracy: 0.6597 - val_loss: 0.8128 - val_accuracy: 0.6494\nEpoch 22/100\n214/214 [==============================] - 24s 110ms/step - loss: 0.8157 - accuracy: 0.6654 - val_loss: 0.7405 - val_accuracy: 0.6938\nEpoch 23/100\n214/214 [==============================] - 23s 108ms/step - loss: 0.8019 - accuracy: 0.6657 - val_loss: 0.7966 - val_accuracy: 0.6450\nEpoch 24/100\n214/214 [==============================] - 24s 112ms/step - loss: 0.8043 - accuracy: 0.6707 - val_loss: 0.7690 - val_accuracy: 0.6756\nEpoch 25/100\n214/214 [==============================] - 23s 105ms/step - loss: 0.7950 - accuracy: 0.6728 - val_loss: 0.7560 - val_accuracy: 0.6869\nEpoch 26/100\n214/214 [==============================] - 23s 109ms/step - loss: 0.7962 - accuracy: 0.6702 - val_loss: 0.7591 - val_accuracy: 0.6756\nEpoch 27/100\n214/214 [==============================] - 24s 113ms/step - loss: 0.7862 - accuracy: 0.6734 - val_loss: 0.7555 - val_accuracy: 0.6888\nEpoch 28/100\n214/214 [==============================] - 23s 108ms/step - loss: 0.7809 - accuracy: 0.6786 - val_loss: 0.7633 - val_accuracy: 0.6819\nEpoch 29/100\n214/214 [==============================] - 23s 109ms/step - loss: 0.7710 - accuracy: 0.6814 - val_loss: 0.8349 - val_accuracy: 0.6356\nEpoch 30/100\n214/214 [==============================] - 23s 109ms/step - loss: 0.7792 - accuracy: 0.6784 - val_loss: 0.7519 - val_accuracy: 0.6787\nEpoch 31/100\n214/214 [==============================] - 24s 110ms/step - loss: 0.7675 - accuracy: 0.6860 - val_loss: 0.8107 - val_accuracy: 0.6556\nEpoch 32/100\n214/214 [==============================] - 23s 109ms/step - loss: 0.7616 - accuracy: 0.6868 - val_loss: 0.7664 - val_accuracy: 0.6712\nEpoch 33/100\n214/214 [==============================] - 23s 107ms/step - loss: 0.7602 - accuracy: 0.6870 - val_loss: 0.7596 - val_accuracy: 0.6850\nEpoch 34/100\n214/214 [==============================] - 25s 115ms/step - loss: 0.7510 - accuracy: 0.6899 - val_loss: 0.7481 - val_accuracy: 0.6775\nEpoch 35/100\n214/214 [==============================] - 24s 110ms/step - loss: 0.7386 - accuracy: 0.6976 - val_loss: 0.7173 - val_accuracy: 0.7013\nEpoch 36/100\n214/214 [==============================] - 23s 110ms/step - loss: 0.7466 - accuracy: 0.6943 - val_loss: 0.7603 - val_accuracy: 0.6888\nEpoch 37/100\n214/214 [==============================] - 24s 113ms/step - loss: 0.7504 - accuracy: 0.6906 - val_loss: 0.7808 - val_accuracy: 0.6731\nEpoch 38/100\n214/214 [==============================] - 23s 107ms/step - loss: 0.7406 - accuracy: 0.6975 - val_loss: 0.7431 - val_accuracy: 0.6969\nEpoch 39/100\n214/214 [==============================] - 24s 110ms/step - loss: 0.7339 - accuracy: 0.6985 - val_loss: 0.7705 - val_accuracy: 0.6906\nEpoch 40/100\n214/214 [==============================] - 23s 107ms/step - loss: 0.7253 - accuracy: 0.7080 - val_loss: 0.7433 - val_accuracy: 0.7000\nEpoch 41/100\n214/214 [==============================] - 23s 108ms/step - loss: 0.7258 - accuracy: 0.6997 - val_loss: 0.7593 - val_accuracy: 0.6781\nEpoch 42/100\n214/214 [==============================] - 24s 110ms/step - loss: 0.7239 - accuracy: 0.7046 - val_loss: 0.7202 - val_accuracy: 0.7019\nEpoch 43/100\n214/214 [==============================] - 23s 107ms/step - loss: 0.7158 - accuracy: 0.7078 - val_loss: 0.7196 - val_accuracy: 0.7106\nEpoch 44/100\n214/214 [==============================] - 24s 112ms/step - loss: 0.7104 - accuracy: 0.7134 - val_loss: 0.7336 - val_accuracy: 0.6994\nEpoch 45/100\n214/214 [==============================] - 23s 109ms/step - loss: 0.7109 - accuracy: 0.7111 - val_loss: 0.7983 - val_accuracy: 0.6606\nEpoch 46/100\n214/214 [==============================] - 23s 110ms/step - loss: 0.7071 - accuracy: 0.7133 - val_loss: 0.7208 - val_accuracy: 0.7000\nEpoch 47/100\n214/214 [==============================] - 24s 113ms/step - loss: 0.7066 - accuracy: 0.7140 - val_loss: 0.7363 - val_accuracy: 0.6919\nEpoch 48/100\n214/214 [==============================] - 24s 110ms/step - loss: 0.7014 - accuracy: 0.7142 - val_loss: 0.6996 - val_accuracy: 0.7244\nEpoch 49/100\n214/214 [==============================] - 24s 110ms/step - loss: 0.6950 - accuracy: 0.7197 - val_loss: 0.7280 - val_accuracy: 0.7069\nEpoch 50/100\n214/214 [==============================] - 24s 114ms/step - loss: 0.6982 - accuracy: 0.7168 - val_loss: 0.7584 - val_accuracy: 0.6925\nEpoch 51/100\n214/214 [==============================] - 24s 111ms/step - loss: 0.6880 - accuracy: 0.7218 - val_loss: 0.6929 - val_accuracy: 0.7219\nEpoch 52/100\n214/214 [==============================] - 25s 115ms/step - loss: 0.6955 - accuracy: 0.7204 - val_loss: 0.7473 - val_accuracy: 0.6831\nEpoch 53/100\n214/214 [==============================] - 23s 110ms/step - loss: 0.6938 - accuracy: 0.7189 - val_loss: 0.7046 - val_accuracy: 0.7163\nEpoch 54/100\n214/214 [==============================] - 25s 115ms/step - loss: 0.6777 - accuracy: 0.7239 - val_loss: 0.7153 - val_accuracy: 0.7088\nEpoch 55/100\n214/214 [==============================] - 25s 115ms/step - loss: 0.6751 - accuracy: 0.7251 - val_loss: 0.7406 - val_accuracy: 0.7175\nEpoch 56/100\n214/214 [==============================] - 24s 111ms/step - loss: 0.6786 - accuracy: 0.7276 - val_loss: 0.7276 - val_accuracy: 0.7081\n","name":"stdout"},{"output_type":"stream","text":"Epoch 57/100\n214/214 [==============================] - 25s 117ms/step - loss: 0.6783 - accuracy: 0.7261 - val_loss: 0.7953 - val_accuracy: 0.6744\nEpoch 58/100\n214/214 [==============================] - 24s 111ms/step - loss: 0.6792 - accuracy: 0.7243 - val_loss: 0.7217 - val_accuracy: 0.7100\nEpoch 59/100\n214/214 [==============================] - 24s 113ms/step - loss: 0.6778 - accuracy: 0.7290 - val_loss: 0.7466 - val_accuracy: 0.7094\nEpoch 60/100\n214/214 [==============================] - 24s 112ms/step - loss: 0.6697 - accuracy: 0.7309 - val_loss: 0.7531 - val_accuracy: 0.6950\nEpoch 61/100\n214/214 [==============================] - 24s 111ms/step - loss: 0.6609 - accuracy: 0.7337 - val_loss: 0.7271 - val_accuracy: 0.6975\nEpoch 62/100\n214/214 [==============================] - 24s 112ms/step - loss: 0.6585 - accuracy: 0.7336 - val_loss: 0.7481 - val_accuracy: 0.7025\nEpoch 63/100\n214/214 [==============================] - 23s 109ms/step - loss: 0.6600 - accuracy: 0.7260 - val_loss: 0.7022 - val_accuracy: 0.7144\nEpoch 64/100\n214/214 [==============================] - 24s 113ms/step - loss: 0.6582 - accuracy: 0.7358 - val_loss: 0.7174 - val_accuracy: 0.7212\nEpoch 65/100\n214/214 [==============================] - 24s 112ms/step - loss: 0.6569 - accuracy: 0.7349 - val_loss: 0.7375 - val_accuracy: 0.7013\nEpoch 66/100\n214/214 [==============================] - 23s 110ms/step - loss: 0.6636 - accuracy: 0.7295 - val_loss: 0.7458 - val_accuracy: 0.7019\nEpoch 67/100\n214/214 [==============================] - 26s 120ms/step - loss: 0.6509 - accuracy: 0.7336 - val_loss: 0.7456 - val_accuracy: 0.7013\nEpoch 68/100\n214/214 [==============================] - 24s 110ms/step - loss: 0.6474 - accuracy: 0.7375 - val_loss: 0.7334 - val_accuracy: 0.7100\nEpoch 69/100\n214/214 [==============================] - 24s 113ms/step - loss: 0.6458 - accuracy: 0.7398 - val_loss: 0.7267 - val_accuracy: 0.7075\nEpoch 70/100\n214/214 [==============================] - 24s 111ms/step - loss: 0.6492 - accuracy: 0.7376 - val_loss: 0.7486 - val_accuracy: 0.7044\nEpoch 71/100\n214/214 [==============================] - 23s 108ms/step - loss: 0.6340 - accuracy: 0.7448 - val_loss: 0.7284 - val_accuracy: 0.7025\nEpoch 72/100\n214/214 [==============================] - 24s 113ms/step - loss: 0.6442 - accuracy: 0.7430 - val_loss: 0.6970 - val_accuracy: 0.7175\nEpoch 73/100\n214/214 [==============================] - 23s 107ms/step - loss: 0.6373 - accuracy: 0.7473 - val_loss: 0.7034 - val_accuracy: 0.7250\nEpoch 74/100\n214/214 [==============================] - 24s 112ms/step - loss: 0.6367 - accuracy: 0.7387 - val_loss: 0.6892 - val_accuracy: 0.7206\nEpoch 75/100\n214/214 [==============================] - 23s 109ms/step - loss: 0.6384 - accuracy: 0.7432 - val_loss: 0.7552 - val_accuracy: 0.7081\nEpoch 76/100\n214/214 [==============================] - 23s 108ms/step - loss: 0.6287 - accuracy: 0.7441 - val_loss: 0.7498 - val_accuracy: 0.7050\nEpoch 77/100\n214/214 [==============================] - 25s 116ms/step - loss: 0.6220 - accuracy: 0.7473 - val_loss: 0.7113 - val_accuracy: 0.7225\nEpoch 78/100\n214/214 [==============================] - 23s 110ms/step - loss: 0.6300 - accuracy: 0.7485 - val_loss: 0.7634 - val_accuracy: 0.6969\nEpoch 79/100\n214/214 [==============================] - 23s 110ms/step - loss: 0.6251 - accuracy: 0.7485 - val_loss: 0.7105 - val_accuracy: 0.7125\nEpoch 80/100\n214/214 [==============================] - 24s 111ms/step - loss: 0.6280 - accuracy: 0.7445 - val_loss: 0.6922 - val_accuracy: 0.7294\nEpoch 81/100\n214/214 [==============================] - 23s 108ms/step - loss: 0.6138 - accuracy: 0.7525 - val_loss: 0.6914 - val_accuracy: 0.7287\nEpoch 82/100\n214/214 [==============================] - 24s 111ms/step - loss: 0.6122 - accuracy: 0.7517 - val_loss: 0.6959 - val_accuracy: 0.7206\nEpoch 83/100\n214/214 [==============================] - 23s 110ms/step - loss: 0.6158 - accuracy: 0.7530 - val_loss: 0.6879 - val_accuracy: 0.7481\nEpoch 84/100\n214/214 [==============================] - 24s 111ms/step - loss: 0.6111 - accuracy: 0.7530 - val_loss: 0.6752 - val_accuracy: 0.7394\nEpoch 85/100\n214/214 [==============================] - 23s 109ms/step - loss: 0.6134 - accuracy: 0.7526 - val_loss: 0.7882 - val_accuracy: 0.6975\nEpoch 86/100\n214/214 [==============================] - 23s 109ms/step - loss: 0.6081 - accuracy: 0.7539 - val_loss: 0.7524 - val_accuracy: 0.6950\nEpoch 87/100\n214/214 [==============================] - 25s 115ms/step - loss: 0.6086 - accuracy: 0.7566 - val_loss: 0.7086 - val_accuracy: 0.7156\nEpoch 88/100\n214/214 [==============================] - 23s 110ms/step - loss: 0.6192 - accuracy: 0.7517 - val_loss: 0.7218 - val_accuracy: 0.7144\nEpoch 89/100\n214/214 [==============================] - 24s 112ms/step - loss: 0.5990 - accuracy: 0.7584 - val_loss: 0.7316 - val_accuracy: 0.7181\nEpoch 90/100\n214/214 [==============================] - 23s 109ms/step - loss: 0.6086 - accuracy: 0.7553 - val_loss: 0.7550 - val_accuracy: 0.6988\nEpoch 91/100\n214/214 [==============================] - 23s 106ms/step - loss: 0.6015 - accuracy: 0.7573 - val_loss: 0.7459 - val_accuracy: 0.7069\nEpoch 92/100\n214/214 [==============================] - 23s 110ms/step - loss: 0.6019 - accuracy: 0.7599 - val_loss: 0.7179 - val_accuracy: 0.7169\nEpoch 93/100\n214/214 [==============================] - 23s 107ms/step - loss: 0.5977 - accuracy: 0.7591 - val_loss: 0.7274 - val_accuracy: 0.7188\nEpoch 94/100\n214/214 [==============================] - 22s 103ms/step - loss: 0.5987 - accuracy: 0.7603 - val_loss: 0.7493 - val_accuracy: 0.6931\nEpoch 95/100\n214/214 [==============================] - 24s 111ms/step - loss: 0.5979 - accuracy: 0.7612 - val_loss: 0.7040 - val_accuracy: 0.7331\nEpoch 96/100\n214/214 [==============================] - 24s 114ms/step - loss: 0.5912 - accuracy: 0.7620 - val_loss: 0.7594 - val_accuracy: 0.7063\nEpoch 97/100\n214/214 [==============================] - 25s 118ms/step - loss: 0.5880 - accuracy: 0.7618 - val_loss: 0.6915 - val_accuracy: 0.7300\nEpoch 98/100\n214/214 [==============================] - 24s 114ms/step - loss: 0.5914 - accuracy: 0.7603 - val_loss: 0.7044 - val_accuracy: 0.7262\nEpoch 99/100\n214/214 [==============================] - 24s 114ms/step - loss: 0.5920 - accuracy: 0.7647 - val_loss: 0.7184 - val_accuracy: 0.7150\nEpoch 100/100\n214/214 [==============================] - 24s 113ms/step - loss: 0.5918 - accuracy: 0.7641 - val_loss: 0.7232 - val_accuracy: 0.7175\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt1 = tf.keras.optimizers.Adam(learning_rate = 1e-4)\nmodel.compile(optimizer = opt1, loss='categorical_crossentropy', metrics=['accuracy'])\n\nhistory1 = model.fit(train_generator,\n                    validation_data = val_generator,\n                    validation_steps = val_generator.samples // val_generator.batch_size,\n                    epochs = 50)\n                    #callbacks = [callbacks])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel.save('resnet50.h5')\n\nmodel.save_weights('resnet50_weights.h5')\n","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest = '../input/fer-dsc-v3/final_data_v5/final_data_v5/Test'\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_directory (test, batch_size=256, class_mode='categorical', target_size=(48,48))\n\nmodel.evaluate(test_generator, steps=4)","execution_count":13,"outputs":[{"output_type":"stream","text":"Found 1649 images belonging to 4 classes.\n4/4 [==============================] - 1s 139ms/step - loss: 0.7108 - accuracy: 0.7207\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"[0.710780918598175, 0.720703125]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}